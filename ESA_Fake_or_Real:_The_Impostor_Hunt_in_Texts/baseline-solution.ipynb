{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28eb6402",
   "metadata": {
    "id": "2-uxElrLnwNy",
    "papermill": {
     "duration": 0.005901,
     "end_time": "2025-06-22T19:14:09.769223",
     "exception": false,
     "start_time": "2025-06-22T19:14:09.763322",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Baseline Solution: Fake or Real - The Impostor Hunt in Texts ðŸ”\n",
    "\n",
    "---\n",
    "\n",
    "Here we provide the baseline solution for the *Fake or Real: The Impostor Hunt in Texts* challenge!\n",
    "In this notebook, we walk you through two **simple, interpretable, and ML-free approaches** to tackle the problem of detecting fake texts.\n",
    "\n",
    "### ðŸ’¡ The overview of first approach:\n",
    "\n",
    "We use the `langdetect` library to analyze each text by identifying the presence of **English vs. non-English words**. Here's the idea:\n",
    "\n",
    "1. **Detect Language**: We break the text into words and determine the language of each.\n",
    "2. **Calculate Proportion**: We then compute the percentage of English words in the entire text.\n",
    "3. **Assign Label**: The text which gets higher percentage of English words is classified as **Real** and its number is saved to the results list.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“¦ Getting Started: Install & Import Required Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872ab685",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:14:09.780522Z",
     "iopub.status.busy": "2025-06-22T19:14:09.780145Z",
     "iopub.status.idle": "2025-06-22T19:14:18.239898Z",
     "shell.execute_reply": "2025-06-22T19:14:18.238668Z"
    },
    "id": "LCyK5ruYWdAp",
    "outputId": "6e27c50a-b46e-49c3-d7cb-1a7c25ad6af3",
    "papermill": {
     "duration": 8.467807,
     "end_time": "2025-06-22T19:14:18.241966",
     "exception": false,
     "start_time": "2025-06-22T19:14:09.774159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install langdetect\n",
    "!pip install pandas\n",
    "!pip install unicodedata2\n",
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4a1e72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:14:18.254982Z",
     "iopub.status.busy": "2025-06-22T19:14:18.254522Z",
     "iopub.status.idle": "2025-06-22T19:14:22.250987Z",
     "shell.execute_reply": "2025-06-22T19:14:22.250005Z"
    },
    "id": "ImkKXISLXN6V",
    "papermill": {
     "duration": 4.005574,
     "end_time": "2025-06-22T19:14:22.253245",
     "exception": false,
     "start_time": "2025-06-22T19:14:18.247671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from langdetect import detect, DetectorFactory\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "import unicodedata\n",
    "\n",
    "import string\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "DetectorFactory.seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b9ab10",
   "metadata": {
    "id": "K9Sj8cJcYooa",
    "papermill": {
     "duration": 0.006209,
     "end_time": "2025-06-22T19:14:22.266228",
     "exception": false,
     "start_time": "2025-06-22T19:14:22.260019",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "### ðŸ“„ Load the Data\n",
    "\n",
    "Now, let's load the data into memory for exploration and processing.\n",
    "\n",
    "We'll use `Pandas` to read the file into a DataFrame, which allows for easy data manipulation and analysis throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0a81296",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:14:22.279068Z",
     "iopub.status.busy": "2025-06-22T19:14:22.278531Z",
     "iopub.status.idle": "2025-06-22T19:14:22.289580Z",
     "shell.execute_reply": "2025-06-22T19:14:22.288550Z"
    },
    "id": "l4NUJlOdjlCU",
    "papermill": {
     "duration": 0.019703,
     "end_time": "2025-06-22T19:14:22.291611",
     "exception": false,
     "start_time": "2025-06-22T19:14:22.271908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_texts_from_dir(dir_path):\n",
    "  \"\"\"\n",
    "  Reads the texts from a given directory and saves them in the pd.DataFrame with columns ['id', 'file_1', 'file_2'].\n",
    "\n",
    "  Params:\n",
    "    dir_path (str): path to the directory with data\n",
    "  \"\"\"\n",
    "  # Count number of directories in the provided path\n",
    "  dir_count = sum(os.path.isdir(os.path.join(root, d)) for root, dirs, _ in os.walk(dir_path) for d in dirs)\n",
    "  data=[0 for _ in range(dir_count)]\n",
    "  print(f\"Number of directories: {dir_count}\")\n",
    "\n",
    "  # For each directory, read both file_1.txt and file_2.txt and save results to the list\n",
    "  i=0\n",
    "  for folder_name in sorted(os.listdir(dir_path)):\n",
    "    folder_path = os.path.join(dir_path, folder_name)\n",
    "    if os.path.isdir(folder_path):\n",
    "      try:\n",
    "        with open(os.path.join(folder_path, 'file_1.txt'), 'r', encoding='utf-8') as f1:\n",
    "          text1 = f1.read().strip()\n",
    "        with open(os.path.join(folder_path, 'file_2.txt'), 'r', encoding='utf-8') as f2:\n",
    "          text2 = f2.read().strip()\n",
    "        index = int(folder_name[-4:])\n",
    "        data[i]=(index, text1, text2)\n",
    "        i+=1\n",
    "      except Exception as e:\n",
    "        print(f\"Error reading directory {folder_name}: {e}\")\n",
    "\n",
    "  # Change list with results into pandas DataFrame\n",
    "  df = pd.DataFrame(data, columns=['id', 'file_1', 'file_2']).set_index('id')\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11fec4b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:14:22.304915Z",
     "iopub.status.busy": "2025-06-22T19:14:22.303667Z",
     "iopub.status.idle": "2025-06-22T19:14:36.137050Z",
     "shell.execute_reply": "2025-06-22T19:14:36.135916Z"
    },
    "id": "9zQl8N5NjsL_",
    "outputId": "75356dc8-934d-4710-c2e3-3aeb11af9427",
    "papermill": {
     "duration": 13.841837,
     "end_time": "2025-06-22T19:14:36.138976",
     "exception": false,
     "start_time": "2025-06-22T19:14:22.297139",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of directories: 95\n",
      "Number of directories: 1068\n"
     ]
    }
   ],
   "source": [
    "# Use the above function to load both train and test data\n",
    "train_path=\"/home/samer/Desktop/competitions/Kaggle challenge Fake or Real: The Impostor Hunt in Texts/fake-or-real-the-impostor-hunt/data/train\"\n",
    "df_train=read_texts_from_dir(train_path)\n",
    "test_path=\"/home/samer/Desktop/competitions/Kaggle challenge Fake or Real: The Impostor Hunt in Texts/fake-or-real-the-impostor-hunt/data/test\"\n",
    "df_test=read_texts_from_dir(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a756431",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:14:36.151640Z",
     "iopub.status.busy": "2025-06-22T19:14:36.151317Z",
     "iopub.status.idle": "2025-06-22T19:14:36.175447Z",
     "shell.execute_reply": "2025-06-22T19:14:36.174434Z"
    },
    "id": "ZfXeI_2kQwOY",
    "outputId": "56436a79-d662-444b-b568-292ea9d4d963",
    "papermill": {
     "duration": 0.032743,
     "end_time": "2025-06-22T19:14:36.177232",
     "exception": false,
     "start_time": "2025-06-22T19:14:36.144489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa44125b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:14:36.192519Z",
     "iopub.status.busy": "2025-06-22T19:14:36.192204Z",
     "iopub.status.idle": "2025-06-22T19:14:36.202290Z",
     "shell.execute_reply": "2025-06-22T19:14:36.201254Z"
    },
    "id": "Bm1krJ-2kUVd",
    "outputId": "4b4a6131-05dd-4fa4-dbf1-0364009b288b",
    "papermill": {
     "duration": 0.020476,
     "end_time": "2025-06-22T19:14:36.204087",
     "exception": false,
     "start_time": "2025-06-22T19:14:36.183611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1faa568b",
   "metadata": {
    "id": "--YetA0tY2GR",
    "papermill": {
     "duration": 0.005923,
     "end_time": "2025-06-22T19:14:36.216367",
     "exception": false,
     "start_time": "2025-06-22T19:14:36.210444",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "### ðŸ·ï¸ Read the Labels\n",
    "\n",
    "Next, weâ€™ll load the **labels** associated with each text sample.\n",
    "These labels indicate which text is **Real** - 1 or 2. The labels will serve as our ground truth for evaluation.\n",
    "\n",
    "Weâ€™ll again use `Pandas` to read the label file into a DataFrame and inspect its structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94319bd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:14:36.230689Z",
     "iopub.status.busy": "2025-06-22T19:14:36.230301Z",
     "iopub.status.idle": "2025-06-22T19:14:36.254993Z",
     "shell.execute_reply": "2025-06-22T19:14:36.253991Z"
    },
    "id": "GH2JbNTTVQoI",
    "outputId": "29ec5bb1-1c7f-4e68-da23-d1aeb26f630a",
    "papermill": {
     "duration": 0.034322,
     "end_time": "2025-06-22T19:14:36.256667",
     "exception": false,
     "start_time": "2025-06-22T19:14:36.222345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load ground truth for train data\n",
    "df_train_gt=pd.read_csv(\"/home/samer/Desktop/competitions/Kaggle challenge Fake or Real: The Impostor Hunt in Texts/fake-or-real-the-impostor-hunt/data/train.csv\")\n",
    "df_train_gt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9eb484",
   "metadata": {
    "id": "C-03yeziJEbd",
    "papermill": {
     "duration": 0.0063,
     "end_time": "2025-06-22T19:14:36.269022",
     "exception": false,
     "start_time": "2025-06-22T19:14:36.262722",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "### ðŸ§ª Baseline solution with English words detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abc5ad29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:14:36.282840Z",
     "iopub.status.busy": "2025-06-22T19:14:36.282441Z",
     "iopub.status.idle": "2025-06-22T19:14:36.291558Z",
     "shell.execute_reply": "2025-06-22T19:14:36.290530Z"
    },
    "id": "JpDNYy3upspd",
    "papermill": {
     "duration": 0.018377,
     "end_time": "2025-06-22T19:14:36.293265",
     "exception": false,
     "start_time": "2025-06-22T19:14:36.274888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def baseline_method_english_word(df):\n",
    "  \"\"\"\n",
    "  This baseline method predicts which of the texts is Real, based on the percentage of English words in each text.\n",
    "  It returns list with predictions.\n",
    "\n",
    "  Params:\n",
    "    df (pd.DataFrame): dataframe with all texts\n",
    "  \"\"\"\n",
    "  # Create lists in which scores will be saved for file_1 (left_scores) and files_2 (right_scores)\n",
    "  left_scores=[0 for _ in range(df.shape[0])]\n",
    "  right_scores=[0 for _ in range(df.shape[0])]\n",
    "  # For each row in the DataFrame and for each element of this row run the algorithm for detecting English words\n",
    "  for j in range(df.shape[0]):\n",
    "    for z in range(df.shape[1]):\n",
    "      sum_english=0\n",
    "      n=10\n",
    "      delete=str.maketrans('', '', string.punctuation+'\\n')\n",
    "      cleaned=df.iloc[j].iloc[z].translate(delete)\n",
    "      text_to_check=cleaned.split(\" \")\n",
    "      text_to_check=[' '.join(text_to_check[i:i+n]) for i in range(0, len(text_to_check),n)]\n",
    "\n",
    "      # Run algorithm for detecting English words\n",
    "      for i in range(len(text_to_check)):\n",
    "        try:\n",
    "          language=detect(text_to_check[i])\n",
    "        except LangDetectException as e:\n",
    "          pass\n",
    "        if language=='en':\n",
    "          sum_english+=1\n",
    "      result=sum_english/len(text_to_check)\n",
    "      if z==0:\n",
    "        left_scores[j]=result\n",
    "      elif z==1:\n",
    "        right_scores[j]=result\n",
    "      else:\n",
    "        print('Wrong')\n",
    "  # Create list with predictions by setting value in list to 1 if the first text is `Real` or 2 when the second seems to be better\n",
    "  predictions=[1 if left_scores[k]>right_scores[k] else 2 for k in range(len(left_scores))]\n",
    "  return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "586922ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:14:36.306416Z",
     "iopub.status.busy": "2025-06-22T19:14:36.306074Z",
     "iopub.status.idle": "2025-06-22T19:14:36.311389Z",
     "shell.execute_reply": "2025-06-22T19:14:36.310365Z"
    },
    "id": "xAIxmZsWqBIV",
    "papermill": {
     "duration": 0.01389,
     "end_time": "2025-06-22T19:14:36.313009",
     "exception": false,
     "start_time": "2025-06-22T19:14:36.299119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_baseline(predictions, gt_list, text='Score with english detection:'):\n",
    "  \"\"\"\n",
    "  Evaluates the predictions for train data, when the ground truth is provided.\n",
    "\n",
    "  Params:\n",
    "    predictions (list): list of predictions\n",
    "    gt_list (list): list of predictions\n",
    "    text (str): text to be printed together with the result\n",
    "  \"\"\"\n",
    "  acc_score = accuracy_score(gt_list, predictions)\n",
    "  print(text,acc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49259059",
   "metadata": {
    "id": "ebsWNCEHQSY_",
    "papermill": {
     "duration": 0.006113,
     "end_time": "2025-06-22T19:14:36.325903",
     "exception": false,
     "start_time": "2025-06-22T19:14:36.319790",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "#### ðŸ“Š Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98106d95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:14:36.339504Z",
     "iopub.status.busy": "2025-06-22T19:14:36.339188Z",
     "iopub.status.idle": "2025-06-22T19:15:08.840950Z",
     "shell.execute_reply": "2025-06-22T19:15:08.839760Z"
    },
    "id": "Rc0m0jpFqTFG",
    "outputId": "6f920985-f8e0-4769-d98f-037875782570",
    "papermill": {
     "duration": 32.516237,
     "end_time": "2025-06-22T19:15:08.848330",
     "exception": false,
     "start_time": "2025-06-22T19:14:36.332093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with english detection: 0.6631578947368421\n"
     ]
    }
   ],
   "source": [
    "# Use the algorithm for the train data and check accuracy\n",
    "predictions_train=baseline_method_english_word(df_train)\n",
    "gt_train=list(df_train_gt['real_text_id'])\n",
    "evaluate_baseline(predictions_train, gt_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c2758bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:15:08.862451Z",
     "iopub.status.busy": "2025-06-22T19:15:08.861513Z",
     "iopub.status.idle": "2025-06-22T19:19:42.522145Z",
     "shell.execute_reply": "2025-06-22T19:19:42.521212Z"
    },
    "id": "gTTLJ-245-v_",
    "papermill": {
     "duration": 273.669614,
     "end_time": "2025-06-22T19:19:42.524423",
     "exception": false,
     "start_time": "2025-06-22T19:15:08.854809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use the algorithm for the test data\n",
    "predictions_test=baseline_method_english_word(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2764c777",
   "metadata": {
    "id": "KOkX2PblSEcX",
    "papermill": {
     "duration": 0.005863,
     "end_time": "2025-06-22T19:19:42.537059",
     "exception": false,
     "start_time": "2025-06-22T19:19:42.531196",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Prepare format for sample solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eed3c17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:19:42.552497Z",
     "iopub.status.busy": "2025-06-22T19:19:42.551105Z",
     "iopub.status.idle": "2025-06-22T19:19:42.568946Z",
     "shell.execute_reply": "2025-06-22T19:19:42.567746Z"
    },
    "id": "kNxJJN2zNhrS",
    "outputId": "ccf38fed-f269-41aa-fbb7-089d83483183",
    "papermill": {
     "duration": 0.02756,
     "end_time": "2025-06-22T19:19:42.570702",
     "exception": false,
     "start_time": "2025-06-22T19:19:42.543142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Change the format of predictions into requested format, as described in Overview section of this competition\n",
    "df_results_test=pd.DataFrame(predictions_test)\n",
    "output_df = df_results_test.copy()\n",
    "output_df.columns = ['real_text_id']\n",
    "output_df.reset_index(inplace=True)\n",
    "output_df.rename(columns={'index': 'id'}, inplace=True)\n",
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e4dc1c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:19:42.585616Z",
     "iopub.status.busy": "2025-06-22T19:19:42.585267Z",
     "iopub.status.idle": "2025-06-22T19:19:42.596840Z",
     "shell.execute_reply": "2025-06-22T19:19:42.595813Z"
    },
    "id": "6zjYu7grIEIG",
    "papermill": {
     "duration": 0.021597,
     "end_time": "2025-06-22T19:19:42.598858",
     "exception": false,
     "start_time": "2025-06-22T19:19:42.577261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_df.to_csv('sample_submission_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74013ee",
   "metadata": {
    "id": "7GNnWQFj9zOx",
    "papermill": {
     "duration": 0.006968,
     "end_time": "2025-06-22T19:19:42.612628",
     "exception": false,
     "start_time": "2025-06-22T19:19:42.605660",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "### ðŸ”¡ Character-Level Baseline\n",
    "\n",
    "In addition to analyzing words, we can explore a **character-level approach** as an alternative baseline.\n",
    "\n",
    "This method evaluates the **proportion of Latin characters** in the text, instead of relying on word-based language detection.\n",
    "\n",
    "By comparing the ratio of English characters to total characters, we generate another set of predictionsâ€”offering a complementary perspective to our word-level strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f29e63bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:19:42.626597Z",
     "iopub.status.busy": "2025-06-22T19:19:42.626265Z",
     "iopub.status.idle": "2025-06-22T19:19:42.636149Z",
     "shell.execute_reply": "2025-06-22T19:19:42.635105Z"
    },
    "id": "khnh9afRauRy",
    "papermill": {
     "duration": 0.018951,
     "end_time": "2025-06-22T19:19:42.637823",
     "exception": false,
     "start_time": "2025-06-22T19:19:42.618872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def is_latin_char(char):\n",
    "  \"\"\"\n",
    "  Detect if given character is from Latin alphabet.\n",
    "\n",
    "  Params:\n",
    "    char (str): given character\n",
    "  \"\"\"\n",
    "  char=str(char)\n",
    "  try:\n",
    "    name=unicodedata.name(char)\n",
    "    return 'LATIN' in name\n",
    "  except ValueError:\n",
    "    return False\n",
    "\n",
    "def baseline_chars_method(df):\n",
    "  \"\"\"\n",
    "  This baseline method predicts which of the texts is Real, based on the percentage of Lating letters in each text.\n",
    "  It returns list with predictions.\n",
    "\n",
    "  Params:\n",
    "    df (pd.DataFrame): dataframe with all texts\n",
    "  \"\"\"\n",
    "  # Create lists in which scores will be saved for file_1 (left_scores) and files_2 (right_scores)\n",
    "  left_scores=[0 for _ in range(df.shape[0])]\n",
    "  right_scores=[0 for _ in range(df.shape[0])]\n",
    "  # For each row in the DataFrame and for each element of this row run the algorithm for detecting Latin chars\n",
    "  for j in range(df.shape[0]):\n",
    "    for z in range(df.shape[1]):\n",
    "      sum_latin=0\n",
    "      count_spaces=0\n",
    "      delete=str.maketrans('', '', string.punctuation+'\\n')\n",
    "      cleaned=df.iloc[j].iloc[z].translate(delete)\n",
    "      \n",
    "      # Run algorithm for detecting Latin chars\n",
    "      for i in range(len(cleaned)):\n",
    "        if cleaned[i] !=' ':\n",
    "          if is_latin_char(cleaned[i]):\n",
    "            sum_latin+=1\n",
    "        else:\n",
    "          count_spaces+=1\n",
    "      if len(cleaned)==0:\n",
    "        result=0\n",
    "      else:\n",
    "        result=sum_latin/(len(cleaned)-count_spaces)\n",
    "      if z==0:\n",
    "        left_scores[j]=result\n",
    "      elif z==1:\n",
    "        right_scores[j]=result\n",
    "      else:\n",
    "        print('Wrong')\n",
    "  # Create list with predictions by setting value in list to 1 if the first text is `Real` or 2 when the second seems to be better\n",
    "  predictions=[1 if left_scores[k]>right_scores[k] else 2 for k in range(len(left_scores))]\n",
    "  return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a7458b",
   "metadata": {
    "id": "F_lCVSPsQYZW",
    "papermill": {
     "duration": 0.006022,
     "end_time": "2025-06-22T19:19:42.650348",
     "exception": false,
     "start_time": "2025-06-22T19:19:42.644326",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "#### ðŸ“Š Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac9d43ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:19:42.664219Z",
     "iopub.status.busy": "2025-06-22T19:19:42.663871Z",
     "iopub.status.idle": "2025-06-22T19:19:42.844611Z",
     "shell.execute_reply": "2025-06-22T19:19:42.843286Z"
    },
    "id": "eCbQibQec3VP",
    "outputId": "c2918670-f055-4c3e-d28a-8bc0ae123f4e",
    "papermill": {
     "duration": 0.190166,
     "end_time": "2025-06-22T19:19:42.846649",
     "exception": false,
     "start_time": "2025-06-22T19:19:42.656483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with latin detection: 0.5368421052631579\n"
     ]
    }
   ],
   "source": [
    "# Use the algorithm for the train data and check accuracy\n",
    "predictions_train_char=baseline_chars_method(df_train)\n",
    "gt_train=list(df_train_gt['real_text_id'])\n",
    "evaluate_baseline(predictions_train_char, gt_train, text='Score with latin detection:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7592d79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:19:42.862281Z",
     "iopub.status.busy": "2025-06-22T19:19:42.861127Z",
     "iopub.status.idle": "2025-06-22T19:19:44.451505Z",
     "shell.execute_reply": "2025-06-22T19:19:44.450535Z"
    },
    "id": "lkwjWMofkodv",
    "papermill": {
     "duration": 1.600083,
     "end_time": "2025-06-22T19:19:44.453272",
     "exception": false,
     "start_time": "2025-06-22T19:19:42.853189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use the algorithm for the test data\n",
    "preds_test_char=baseline_chars_method(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f792a43e",
   "metadata": {
    "id": "CsJnAYP3S9yj",
    "papermill": {
     "duration": 0.006786,
     "end_time": "2025-06-22T19:19:44.466326",
     "exception": false,
     "start_time": "2025-06-22T19:19:44.459540",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Prepare format for sample solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b192d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:19:44.480624Z",
     "iopub.status.busy": "2025-06-22T19:19:44.480258Z",
     "iopub.status.idle": "2025-06-22T19:19:44.495159Z",
     "shell.execute_reply": "2025-06-22T19:19:44.494043Z"
    },
    "id": "5P5gSo8SSQJa",
    "outputId": "23d79869-c0f2-4627-e60b-c90c023a1e30",
    "papermill": {
     "duration": 0.02428,
     "end_time": "2025-06-22T19:19:44.496791",
     "exception": false,
     "start_time": "2025-06-22T19:19:44.472511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Change the format of predictions into requested format, as described in Overview section of this competition\n",
    "df_results_test_char=pd.DataFrame(preds_test_char)\n",
    "output_df_char = df_results_test_char.copy()\n",
    "output_df_char.columns = ['real_text_id']\n",
    "output_df_char.reset_index(inplace=True)\n",
    "output_df_char.rename(columns={'index': 'id'}, inplace=True)\n",
    "output_df_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c687dc84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T19:19:44.512039Z",
     "iopub.status.busy": "2025-06-22T19:19:44.511670Z",
     "iopub.status.idle": "2025-06-22T19:19:44.518889Z",
     "shell.execute_reply": "2025-06-22T19:19:44.517818Z"
    },
    "id": "K-CpwiJ6DSL7",
    "papermill": {
     "duration": 0.017127,
     "end_time": "2025-06-22T19:19:44.520774",
     "exception": false,
     "start_time": "2025-06-22T19:19:44.503647",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_df_char.to_csv('sample_submission_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433bac7d",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "## Detecting fakes using google genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f9de4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from google import genai\n",
    "import google.genai as genai\n",
    "from google.genai import types\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "def get_response(contents_1):\n",
    "    \"\"\"receive a string of the prompt for the model and \n",
    "    returns a string of the article \n",
    "    \n",
    "    Args:\n",
    "        contents_1 (str): The prompt to send to the generative model.\n",
    "    \"\"\"\n",
    "    # Define the model name to use\n",
    "    model_name = \"gemma-3-27b-it\" # Corrected model name based on traceback\n",
    "    # Initialize the client with the API key\n",
    "    client = genai.Client(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "    x = True\n",
    "    # Loop to handle potential API errors and retry\n",
    "    while x == True:\n",
    "        try:\n",
    "            # Generate content using the specified model and prompt\n",
    "            response_1 = client.models.generate_content(\n",
    "                model=model_name,\n",
    "                contents=contents_1,\n",
    "                )\n",
    "            # Strip whitespace from the response text\n",
    "            result_1 = response_1.text.strip()\n",
    "            x = False\n",
    "            return result_1\n",
    "        except:\n",
    "            # If an error occurs, wait for 30 seconds before retrying\n",
    "            time.sleep(30)\n",
    "            continue\n",
    "\n",
    "    return result_1\n",
    "\n",
    "def process_articles(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Iterates over a DataFrame, reading file paths from 'file_1' and 'file_2'\n",
    "    columns, and prints their contents.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with 'file_1' and 'file_2' columns\n",
    "                           containing file paths.\n",
    "    \"\"\"\n",
    "    print(\"--- Starting to process articles ---\")\n",
    "    predictions = []\n",
    "    counter = 0\n",
    "    results = [\"Article 1\", \"Article 2\"]\n",
    "    turns = 0\n",
    "    # itertuples() is generally more performant than iterrows()\n",
    "    for row in df.itertuples(index=False):\n",
    "        # Using getattr to access columns by name from the named tuple\n",
    "        print(\"this is row\", row)\n",
    "        f1 = getattr(row, 'file_1')\n",
    "        f2 = getattr(row, 'file_2')\n",
    "\n",
    "        \n",
    "        # Define the model name and initialize the client\n",
    "        model_name = \"gemma-3-27b-it\" # Corrected model name based on traceback\n",
    "        client = genai.Client(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "        \n",
    "\n",
    "        # models = client.models.list()\n",
    "        # for m in models:\n",
    "        #     print(m)\n",
    "        # break\n",
    "        \n",
    "        # Create the prompt for the generative model\n",
    "        contents_1 = f\"\"\"\n",
    "                        Article 1: {f1}\n",
    "                        Article 2: {f2}\n",
    "\n",
    "                        Only one of the articles above is real, and the other is fake.\n",
    "                        Let's think step by step. First, analyze both articles to find signs of being fake or real. Second, compare them to determine which one is more likely to be real. Finally, state your conclusion.\n",
    "\n",
    "                        take into consideration that only texts in english language can be real and all other languages are fake.\n",
    "                        \n",
    "                        regardless of anything do not include the thinking steps in the output and return only one word referring to the real article [Article 1 or Article 2].\n",
    "                        \n",
    "                        Pay high attention please because it matters a lot.\n",
    "                        \"\"\"\n",
    "        \n",
    "\n",
    "        try: \n",
    "            # Generate content from the model\n",
    "            response_1 = client.models.generate_content(\n",
    "                model=model_name,\n",
    "                contents=contents_1,\n",
    "                )\n",
    "\n",
    "        except:\n",
    "            # Wait for 30 seconds if there's an API error\n",
    "            time.sleep(30)\n",
    "        # Get the text from the response\n",
    "        result_1 = response_1.text.strip()\n",
    "        counter+=1\n",
    "        print(f\"Processed row {counter}: {result_1}\")\n",
    "        \n",
    "        # Convert the model's text response to a prediction (1 or 2)\n",
    "        if result_1 == \"Article 1\":\n",
    "            predict = 1\n",
    "            print(\"predict\", predict)\n",
    "            predictions.append(predict)\n",
    "        elif result_1 == \"Article 2\":\n",
    "            predict = 2\n",
    "            print(\"predict\", predict)\n",
    "            predictions.append(predict)\n",
    "        else:\n",
    "            # If the response is not as expected, retry up to 10 times\n",
    "            while result_1 not in results and turns < 10:\n",
    "                result_1 = get_response(contents_1)\n",
    "                print(f\"Processed row {counter}: {result_1}\")\n",
    "                turns += 1\n",
    "            else:\n",
    "                # Process the result from retries\n",
    "                if result_1 == \"Article 1\":\n",
    "                    predict = 1\n",
    "                    print(\"predict\", predict)\n",
    "                    predictions.append(predict)\n",
    "                elif result_1 == \"Article 2\":\n",
    "                    predict = 2\n",
    "                    print(\"predict\", predict)\n",
    "                    predictions.append(predict)\n",
    "                else:\n",
    "                    # Default to 1 if still no valid response\n",
    "                    predict = 1\n",
    "                    print(\"predict\", predict)\n",
    "                    predictions.append(predict)\n",
    "\n",
    "\n",
    "            \n",
    "    print(\"Predictions:\", predictions)\n",
    "    # Load ground truth labels for evaluation\n",
    "    df_train_gt=pd.read_csv(os.getenv(\"df_train_gt\"))\n",
    "    df_train_gt\n",
    "    y_true = [int(row[\"real_text_id\"]) for index, row in df_train_gt.iterrows()]\n",
    "    print(\"y_true\", y_true)\n",
    "    \n",
    "    # Calculate and print the accuracy score\n",
    "    # acc = accuracy_score(y_true, predictions)\n",
    "    # print(\"Accuracy for the model: \", acc)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# This block runs when the script is executed directly\n",
    "if __name__ == '__main__':\n",
    "    # Define paths for train and test data\n",
    "    train_path=os.getenv(\"train_path\")\n",
    "    # Load training data\n",
    "    df_train=read_texts_from_dir(train_path)\n",
    "    test_path=os.getenv(\"test_path\")\n",
    "    # Load test data\n",
    "    df_test=read_texts_from_dir(test_path)\n",
    "\n",
    "    # Process the training data to get predictions\n",
    "    predictions = process_articles(df_test)\n",
    "    # Create a DataFrame from the predictions\n",
    "    df_results_test_char=pd.DataFrame(predictions)\n",
    "    output_df_char = df_results_test_char.copy()\n",
    "    output_df_char.columns = ['real_text_id']\n",
    "    output_df_char.reset_index(inplace=True)\n",
    "    output_df_char.rename(columns={'index': 'id'}, inplace=True)\n",
    "    output_df_char\n",
    "    # Save the results to a CSV file (commented out)\n",
    "    output_df_char.to_csv('submission_5.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 12693370,
     "sourceId": 99811,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 340.921147,
   "end_time": "2025-06-22T19:19:45.451603",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-22T19:14:04.530456",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
