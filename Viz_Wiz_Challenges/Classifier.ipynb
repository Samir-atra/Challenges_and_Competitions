{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f4850f7"
      },
      "source": [
        "# **VizWiz Image Classification with InceptionV3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5f86b33"
      },
      "source": [
        "### This notebook demonstrates how to perform image classification on the VizWiz dataset using a pre-trained InceptionV3 model from TensorFlow. It covers loading the pre-trained weights, saving and loading the model, and making predictions on new images.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bde09ab0"
      },
      "source": [
        "This cell imports necessary libraries for building and training a TensorFlow model, including modules for file path manipulation, image handling, and numerical operations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07af77f8"
      },
      "source": [
        "# Imports\n",
        "\n",
        "import tensorflow as tf\n",
        "import pathlib\n",
        "import os\n",
        "import pathlib\n",
        "import IPython\n",
        "import json\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Note: Some imports might be redundant, consider cleaning them up if not used."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cae3fd6"
      },
      "source": [
        "This cell downloads the pre-trained weights of the InceptionV3 model from the ImageNet dataset. InceptionV3 is a widely used convolutional neural network architecture for image classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74794cff"
      },
      "source": [
        "# Downloading the weights of the base model\n",
        "\n",
        "# InceptionV3 model pre-trained on ImageNet\n",
        "base_model = tf.keras.applications.inception_v3.InceptionV3(\n",
        "    input_shape = (299, 299, 3), # Expected input image shape\n",
        "    include_top = True, # Include the fully-connected layer at the top\n",
        "    weights = \"imagenet\", # Use weights pre-trained on ImageNet\n",
        "    classes=1000, # Number of classes in ImageNet\n",
        "    classifier_activation=\"softmax\", # Activation function for the output layer\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33c07f6c"
      },
      "source": [
        "This cell saves the downloaded InceptionV3 base model to a specified file path in HDF5 format (`.h5`). This allows for later loading of the model without needing to re-download the weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8f6566a"
      },
      "source": [
        "# Saving the downloaded base_model\n",
        "\n",
        "# Define the path to save the model\n",
        "saving_path = pathlib.Path('/home/samer/Desktop/Beedoo/VizWiz/SavedBaseModel.h5')\n",
        "\n",
        "# Save the model in HDF5 format\n",
        "base_model.save(saving_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6972a207"
      },
      "source": [
        "This cell loads the previously saved InceptionV3 model and sets its layers to be non-trainable. It also defines preprocessing and augmentation layers for image data, although the augmentation layers are currently commented out. The cell then defines the model's input and connects it to the base model, applying the InceptionV3 preprocessing. The commented-out code suggests an intention to potentially add more layers, compile the model, and use KerasTuner for hyperparameter tuning and training, but currently, it only defines the model structure and prints its summary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87ef8bb3"
      },
      "source": [
        "# Model Definition and Loading\n",
        "\n",
        "# Define the path to the saved model\n",
        "model_path = pathlib.Path('/home/samer/Desktop/Beedoo/VizWiz/SavedBaseModel.h5')\n",
        "\n",
        "# Loading base_model\n",
        "base_model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "# Setting the base model as non-trainable to use it as a fixed feature extractor\n",
        "base_model.trainable = False\n",
        "\n",
        "# Define preprocessing layers\n",
        "# Rescaling to (1, -1) range required for inceptionV3 model\n",
        "rescaling = tf.keras.Sequential([\n",
        "  tf.keras.layers.Rescaling(scale=1 / 127.5, offset=-1)\n",
        "])\n",
        "\n",
        "# Define augmentation layers (currently commented out)\n",
        "# Applying augmentations to the images\n",
        "augmentation = tf.keras.Sequential([\n",
        "   tf.keras.layers.RandomFlip(\"horizontal\"),\n",
        "   tf.keras.layers.RandomRotation(0.1)\n",
        "])\n",
        "\n",
        "# def build_model(hp): # Commented out function for KerasTuner\n",
        "\n",
        "# Define the model's input layer\n",
        "inputs = tf.keras.Input(shape=(299, 299, 3))\n",
        "\n",
        "# Apply preprocessing and pass through the base model\n",
        "# x = augmentation(inputs) # Apply augmentation (commented out)\n",
        "# x = rescaling(x) # Apply rescaling (commented out)\n",
        "x = tf.keras.applications.inception_v3.preprocess_input(inputs) # Apply InceptionV3 specific preprocessing\n",
        "x = base_model(x, training=False) # Pass through the base model in inference mode\n",
        "\n",
        "# Add more layers (commented out)\n",
        "# x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "# outputs = tf.keras.layers.Dense(1000, activation='softmax')(x) # \"softmax\" in the final layer for decision making\n",
        "\n",
        "# Create the functional model\n",
        "model = tf.keras.Model(inputs, x)\n",
        "\n",
        "# learning_rate = hp.Float(\"lr\", min_value=1e-5, max_value=1e-3, sampling=\"log\") # Commented out learning rate for KerasTuner\n",
        "\n",
        "# Compile the model (commented out)\n",
        "# model.compile(\n",
        "#     optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0005), # compiling with low learning rate\n",
        "#     loss=tf.losses.SparseCategoricalCrossentropy(),\n",
        "#     metrics=['accuracy'],\n",
        "#     run_eagerly = True)\n",
        "\n",
        "#  return model # Commented out return for KerasTuner\n",
        "\n",
        "# KerasTuner setup (commented out)\n",
        "# tuner = keras_tuner.RandomSearch(\n",
        "#     hypermodel=build_model,\n",
        "#     objective=\"val_accuracy\",\n",
        "#     max_trials=3,\n",
        "#     executions_per_trial=2,\n",
        "#     overwrite=True,\n",
        "#     directory=\"/content/drive/MyDrive/Transfer\",\n",
        "#     project_name=\"Tuner\",\n",
        "# )\n",
        "\n",
        "# tuner.search_space_summary() # Commented out KerasTuner summary\n",
        "\n",
        "# tuner.search(dataset_path, epochs=5, validation_data = dataset_path_val) # Commented out KerasTuner search\n",
        "\n",
        "# tuner.results_summary() # Commented out KerasTuner results\n",
        "\n",
        "# Model fitting (commented out)\n",
        "# model.fit( # fitting the whole model for non-trainable base\n",
        "#     dataset_path,\n",
        "#     epochs=1,\n",
        "#     validation_data = dataset_path_val)\n",
        "    # validation_data = dataset_path_val)\n",
        "    #verbose = 1)\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "569e104d"
      },
      "source": [
        "This cell defines paths to training, validation, and test data directories. It then compiles the loaded model with an Adam optimizer, sparse categorical crossentropy loss (assuming integer labels), and accuracy metric. The code then iterates through image files in the validation directory, loads each image, preprocesses it, makes a prediction using the model, and stores the predicted class index in a dictionary with the filename as the key. Finally, it prints the dictionary and saves it to a JSON file. A time delay is included every 600 predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "846a3ef5"
      },
      "source": [
        "# Predicting on Validation Data\n",
        "\n",
        "# Define paths to data directories\n",
        "train_data_path = pathlib.Path('/home/samer/Desktop/Beedoo/VizWiz/trai/')\n",
        "val_data_path = pathlib.Path('/home/samer/Desktop/Beedoo/VizWiz/val/')\n",
        "data_path_test = pathlib.Path('/home/samer/Desktop/Beedoo/VizWiz/test/')\n",
        "\n",
        "# Compile the loaded model for prediction\n",
        "model.compile(                                                   # compiling the loaded model\n",
        "    optimizer='adam', # Using Adam optimizer\n",
        "    loss=tf.losses.SparseCategoricalCrossentropy(from_logits= True), # Using SparseCategoricalCrossentropy loss\n",
        "    metrics=['accuracy']) # Monitoring accuracy\n",
        "\n",
        "# Initialize a dictionary to store predictions and a counter\n",
        "dictionary = dict()\n",
        "counter = 0\n",
        "\n",
        "# Iterate through image files in the validation directory\n",
        "for file in os.listdir(os.path.join(val_data_path)):\n",
        "    image_path = os.path.join(val_data_path, file)\n",
        "\n",
        "    # Load and preprocess the image\n",
        "    image = tf.keras.utils.load_img(image_path,\n",
        "                                    target_size=(299,299)) # Resize image to target size\n",
        "    input_arr = tf.keras.utils.img_to_array(image) # Convert image to numpy array\n",
        "    input_arr = np.array([input_arr])  # Convert single image to a batch.\n",
        "    # plt.imshow(image) # Display image (commented out)\n",
        "    # plt.show() # Show plot (commented out)\n",
        "\n",
        "    # Make a prediction\n",
        "    predictions = model.predict(input_arr)\n",
        "    pred = np.argmax(predictions, axis=1) # Get the index of the predicted class\n",
        "\n",
        "    # Store the prediction in the dictionary\n",
        "    dictionary[file] = int(pred[0])\n",
        "    counter +=1\n",
        "\n",
        "    # Introduce a time delay every 600 predictions\n",
        "    if counter % 600 == 0:\n",
        "        time.sleep(5) # Pause for 5 seconds\n",
        "\n",
        "# Print the dictionary of predictions\n",
        "print(dictionary)\n",
        "\n",
        "# Writing to sample.json\n",
        "# Open the JSON file in append mode and save the dictionary\n",
        "with open(\"/home/samer/Desktop/Beedoo/VizWiz/sample_val.json\", \"a\") as outfile:\n",
        "    json_object = json.dump(dictionary, outfile)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tensorflow",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}