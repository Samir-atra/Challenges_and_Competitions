{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"},"colab":{"provenance":[]}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Setup, Data Preparation Imports, and Initial Visualization** üõ†Ô∏è\n\nThis cell performs the essential **initial setup** for the earthquake prediction project. It loads necessary libraries for data handling, machine learning, and visualization, and initializes a key data preprocessing utility.\n\n### üìö **Core Libraries**\n* **`csv`** and **`numpy` (`np`)**: Used for basic file reading and efficient numerical/array operations.\n* **`tensorflow` (`tf`)**: The primary library for **building, compiling, and training the neural network model**.\n* **`matplotlib.pyplot` (`plt`)**: Essential for **visualization** of the training results (accuracy and loss).\n\n### ‚öôÔ∏è **Data Preparation**\n* **`sklearn.impute.SimpleImputer`**: A crucial utility for **handling missing data** (NaN values).\n* The code initializes an imputer (`imp`) set to use the **mean strategy** to fill in any missing features, ensuring the dataset is clean and ready for model training.\n\n### üìà **Post-Training Visualization**\n* The final lines plot the **model's training history** (`fitting.history`).\n* It separates the plots for **accuracy** and **loss** to visually assess model performance and convergence over the training epochs.\n\n**In summary, this cell imports the necessary machine learning toolkit and defines the initial strategy for handling imperfect real-world data.**\n","metadata":{"id":"ZWm_aQhFKaZA"}},{"cell_type":"code","source":"# Import necessary libraries\nimport csv\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.impute import SimpleImputer\nimport matplotlib.pyplot as plt\n\n\n# Initialize an imputer to handle missing data using the mean strategy\nimp = SimpleImputer(missing_values=np.nan, strategy='mean',keep_empty_features=True)\n\n# Load the dataset from 'train.csv'\n# skip_header=1 skips the header row\ndata = np.genfromtxt('train.csv', delimiter=',', skip_header=1)\n\n# Separate features (inputs) and labels (outputs)\n# The first 35 columns are features, the 36th column is the label\ninputs = data[:, 0:35]\noutputs = data[:, 36]\n\n# Extract the 7th column (index 6) from the inputs for testing (optional)\ntest = inputs[:, 6]\nprint(\"Sample of the 7th feature column:\", test) # Print a sample of the extracted column\n\n# Fit the imputer on the training data and transform it to handle missing values\nimp.fit(inputs)\ninputs=imp.transform(inputs)\n\n# Define the deep learning model structure using a Sequential model\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Flatten(), # Flatten the input layer\n    tf.keras.layers.Dense(55, activation = \"relu\"), # First dense layer with ReLU activation\n    tf.keras.layers.Dense(20,activation= 'relu'), # Second dense layer with ReLU activation\n    tf.keras.layers.Dense(20,activation= 'relu'), # Third dense layer with ReLU activation\n    tf.keras.layers.Dense(20,activation= 'relu'), # Fourth dense layer with ReLU activation\n    tf.keras.layers.Dense(20,activation= 'relu'), # Fifth dense layer with ReLU activation\n    tf.keras.layers.Dense(4, activation = 'softmax') # Output layer with Softmax activation for multi-class classification\n])\n\n# Compile the model\nmodel.compile(\n    loss = 'sparse_categorical_crossentropy', # Loss function for multi-class classification\n    optimizer = tf.keras.optimizers.Adam(learning_rate= 0.00001), # Adam optimizer with a specified learning rate\n    metrics= ['accuracy'], # Metric to monitor during training\n)\n\n# Train the model\n# fitting stores the training history\nfitting = model.fit(\n    inputs, # Input features\n    outputs, # Output labels\n    epochs = 100000 # Number of training epochs\n)\n\n# Print the training accuracy history\nprint(\"Training Accuracy History:\", fitting.history['accuracy'])\n\n# Visualize the training accuracy\nplt.plot(fitting.history['accuracy'])\nplt.title('Model Accuracy') # Add a title to the plot\nplt.xlabel('Epoch') # Add a label to the x-axis\nplt.ylabel('Accuracy') # Add a label to the y-axis\nplt.show() # Display the plot\n\n# Visualize the training loss\nplt.plot(fitting.history['loss'])\nplt.title('Model Loss') # Add a title to the plot\nplt.xlabel('Epoch') # Add a label to the x-axis\nplt.ylabel('Loss') # Add a label to the y-axis\nplt.show() # Display the plot","metadata":{"id":"uL_fURmtJ5tJ"},"outputs":[],"execution_count":null}]}