{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/samerattrah/turtlevision-challenge?scriptVersionId=268094607\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Jellyfish and Plastic Pollution Classification\n\nThis notebook demonstrates a transfer learning approach using InceptionV3 to classify images of different types of jellyfish and plastic pollution. The process involves loading the dataset, fine-tuning a pre-trained InceptionV3 model, and generating predictions on a test set.","metadata":{"id":"93a1d5ea"}},{"cell_type":"markdown","source":"This cell imports the necessary libraries for the project, including TensorFlow, Keras Tuner, NumPy, OS, Pathlib, Matplotlib, IPython, Sys, OpenCV, and CSV.","metadata":{"id":"ae5c6542"}},{"cell_type":"code","source":"# This cell imports the necessary libraries for the project.\n\nimport tensorflow as tf\nimport keras_tuner\nimport numpy as np\nimport os\nimport pathlib\nimport matplotlib.pyplot as plt\nimport IPython\nimport sys\nimport cv2\nimport csv","metadata":{"id":"4b4c3769"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This cell loads the training, validation, and test datasets using `tf.keras.utils.image_dataset_from_directory`. It specifies the data paths, image size, color mode, batch size, and splits the training data into training and validation sets.","metadata":{"id":"3f375e5e"}},{"cell_type":"code","source":"# This cell loads the training, validation, and test datasets.\n\n# Dataset loading\ndata_path = pathlib.Path('/home/samer/Desktop/Beedoo/ML_Olympiad/mlo2024mlact/MLAct-MLO2024-Dataset/train/')\ndata_path_test = pathlib.Path('/home/samer/Desktop/Beedoo/ML_Olympiad/mlo2024mlact/MLAct-MLO2024-Dataset/test/')\nAUTOTUNE = tf.data.AUTOTUNE\n\n# Training and validation datasets\ndataset_path, dataset_path_val = tf.keras.utils.image_dataset_from_directory(\n    data_path,\n    labels='inferred',\n    validation_split=0.2,\n    subset='both',\n    seed=1,\n    batch_size=16,\n    image_size=(244, 244),\n    color_mode=\"rgb\",\n    shuffle=True\n)\n\n# Test dataset\ndataset_path_test = tf.keras.utils.image_dataset_from_directory(\n    data_path_test,\n    labels='inferred',\n    seed=2,\n    batch_size=1,\n    image_size=(244, 244),\n    color_mode=\"rgb\",\n    shuffle=True\n)","metadata":{"id":"08e027ff"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This cell downloads the pre-trained InceptionV3 model weights from ImageNet. The `include_top=False` argument removes the classification layer, allowing us to fine-tune the model for our specific task.","metadata":{"id":"194899d5"}},{"cell_type":"code","source":"# This cell downloads the pre-trained InceptionV3 model weights from ImageNet.\n\n# downloading the weights of the base model\nbase_model = tf.keras.applications.InceptionV3(\n    input_shape=(244, 244, 3),\n    include_top=False,  # Remove the classification layer\n    weights=\"imagenet\"\n)","metadata":{"id":"060fd08b"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This cell saves the downloaded base model to a file named 'SavedBaseModel.h5'. This allows us to load the model later without re-downloading the weights.","metadata":{"id":"d0601bc0"}},{"cell_type":"code","source":"# This cell saves the downloaded base model to a file.\n\n# saving the downloaded base_model\nsaving_path = pathlib.Path('SavedBaseModel.h5')\nbase_model.save(saving_path)","metadata":{"id":"bfa539e6"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This cell loads the saved base model, sets it as non-trainable, and defines data preprocessing and augmentation layers. It then builds the classification model by adding a global average pooling layer and a dense output layer with softmax activation. The model is compiled with an Adam optimizer and sparse categorical crossentropy loss. It is then trained for 15 epochs with the base model frozen. Afterwards, the base model is made trainable, and the batch normalization layers are frozen. The model is recompiled with a lower learning rate and trained for another 35 epochs.","metadata":{"id":"03a94b20"}},{"cell_type":"code","source":"# This cell loads and trains the model.\n\n#Model\nmodel_path = pathlib.Path('SavedBaseModel.h5')\n\n# Loading base_model\nbase_model = tf.keras.models.load_model(model_path)\n\n# Setting the base model as non-trainable initially\nbase_model.trainable = False\n\n# Data preprocessing and augmentation layers\nrescaling = tf.keras.Sequential([\n    # Rescaling to (1, -1) range required for inceptionV3 model\n    tf.keras.layers.Rescaling(scale=1 / 127.5, offset=-1)\n])\naugmentation = tf.keras.Sequential([\n    # Applying augmentations on the images\n    tf.keras.layers.RandomFlip(\"horizontal\"),\n    tf.keras.layers.RandomRotation(0.1)\n])\n\n# Build the classification model\ninputs = tf.keras.Input(shape=(244, 244, 3))\n# x = rescaling(inputs) # Optional: apply rescaling\n# x = augmentation(x) # Optional: apply augmentation\nx = tf.keras.applications.inception_v3.preprocess_input(inputs) # Preprocess input for InceptionV3\nx = base_model(x, training=False)  # Pass through the base model\nx = tf.keras.layers.GlobalAveragePooling2D()(x) # Add a global average pooling layer\noutputs = tf.keras.layers.Dense(6, activation='softmax')(x)  # Add a dense output layer with softmax activation\nmodel = tf.keras.Model(inputs, outputs)\n\n# Compile the model with a low learning rate\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.00029979988271190114),\n    loss=tf.losses.SparseCategoricalCrossentropy(),\n    metrics=['accuracy'],\n    run_eagerly=True  # Set to True for easier debugging\n)\n\n  # return model\n\n# build_model(keras_tuner.HyperParameters())\n\n# tuner = keras_tuner.RandomSearch(\n#     hypermodel=build_model,\n#     objective=\"val_loss\",\n#     max_trials=6,\n#     executions_per_trial=2,\n#     overwrite=True,\n#     directory=\"/home/samer/Desktop/Beedoo/ML_Olympiad/mlo2024mlact/MLAct-MLO2024-Dataset/\",\n#     project_name=\"Tuner\",\n# )\n\n# tuner.search_space_summary()\n\n# tuner.search(dataset_path, epochs=20, validation_data = dataset_path_val)\n\n# tuner.results_summary()\n\n\nmodel.fit(                                                               # fitting the whole model for non-trainable base\n    dataset_path,\n    epochs=15,\n    validation_data=dataset_path_val\n)\n\nmodel.summary()\n\n# Switch the base_model to trainable for fine-tuning\nbase_model.trainable = True\n\n# Freeze all batchnormalization layers of the base_model to not lose weights\nfor layer in base_model.layers:\n    if isinstance(layer, tf.keras.layers.BatchNormalization):\n        layer.trainable = False\n\n# Recompile the model with a lower learning rate for fine-tuning\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.000001),\n    loss=tf.losses.SparseCategoricalCrossentropy(),\n    metrics=['accuracy'],\n    run_eagerly=True  # Set to True for easier debugging\n)\n\n# Fit the model for another 35 epochs with the base model unfrozen\nmodel.fit(\n    dataset_path,\n    epochs=50,  # Total epochs = 15 + 35\n    initial_epoch=15, # Start from epoch 15\n    validation_data=dataset_path_val\n)\n\n# model.evaluate(dataset_path_test, batch_size=5, verbose=1) # Optional: evaluate on test set\n\nmodel.summary()","metadata":{"id":"8f229bdf"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This cell saves the trained model to a specified directory in the TensorFlow SavedModel format. This allows the model to be loaded and used later for making predictions.","metadata":{"id":"ca093f8b"}},{"cell_type":"code","source":"# This cell saves the trained model.\n\n# save model\nsaving_path = pathlib.Path('/home/samer/Desktop/Beedoo/ML_Olympiad/mlo2024mlact/MLAct-MLO2024-Dataset/saved_model/')\n\ntf.keras.models.save_model(model,\n                           saving_path,\n                           overwrite=True,\n                           save_format='tf'  # Save in TensorFlow SavedModel format\n                           )","metadata":{"id":"04ec943d"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This cell loads the saved model from the specified directory and compiles it. The `compile=True` argument ensures that the model is ready for making predictions.","metadata":{"id":"9e7fbe4c"}},{"cell_type":"code","source":"# This cell loads the saved model for prediction.\n\n# load and compile prediction model\nloading_path = pathlib.Path('/home/samer/Desktop/Beedoo/ML_Olympiad/mlo2024mlact/MLAct-MLO2024-Dataset/saved_model/')\nloaded_model = tf.keras.models.load_model(loading_path, compile=True)\n\n# Compile the loaded model\nloaded_model.compile(\n    optimizer='adam',\n    loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics=['accuracy']\n)","metadata":{"id":"af791fe7"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This cell defines a function `csv_writer` that takes a filename, fields (header row), and data as input and writes the data to a CSV file. It appends to the file if it already exists.","metadata":{"id":"8e0023f9"}},{"cell_type":"code","source":"# This cell defines a function to write data to a CSV file.\n\ndef csv_writer(filename, fields, data):\n    \"\"\"\n    Writes data to a CSV file.\n\n    Args:\n        filename (str): The name of the CSV file.\n        fields (list): A list of strings representing the header row.\n        data (list of tuples): A list of tuples, where each tuple represents a row of data.\n\n    Returns:\n        bool: True if the data was successfully written to the file.\n    \"\"\"\n    csvfile = filename\n    with open(csvfile, mode=\"a\", newline='') as first:  # Use mode=\"a\" to append, newline='' to prevent extra blank rows\n        csvwriter = csv.writer(first)\n        csvwriter.writerow(fields)  # Write the header row\n        csvwriter.writerows(data)  # Write the data rows\n\n    return True","metadata":{"id":"f127fd71"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This cell iterates through the test dataset, loads each image, preprocesses it, and makes a prediction using the loaded model. It then maps the predicted class index to the corresponding class name and appends the image filename and predicted class to a list. Finally, it uses the `csv_writer` function to write the predictions to a CSV file named \"TurtleVisionChallenge_Predictions_fineTuned.csv\".","metadata":{"id":"1a22ae62"}},{"cell_type":"code","source":"# This cell generates predictions on the test set and writes them to a CSV file.\n\n# file creation for the predicted labels list\nsubmit = []\npred_data_path = pathlib.Path(\"/home/samer/Desktop/Beedoo/ML_Olympiad/mlo2024mlact/MLAct-MLO2024-Dataset/test/\")\n\n# Iterate through the test dataset\nfor dir1 in os.listdir(pred_data_path):\n    for file in os.listdir(os.path.join(pred_data_path, dir1)):\n        image_path = os.path.join(pred_data_path, dir1, file)\n\n        # Load and preprocess the image\n        image = cv2.imread(image_path, cv2.COLOR_BGR2RGB)\n        image = np.array(image)\n        image = image.astype(\"float32\")\n        pred_image = np.reshape(image, (1, 244, 244, 3))\n\n        # Make a prediction\n        predictions = loaded_model.predict(pred_image)\n        pred = np.argmax(predictions, axis=1)\n        print(\"this is pred: \", pred)\n\n        # Map the predicted class index to the class name\n        if pred == 0:\n            PredictedClass = \"'barrel_jellyfish'\"\n            print(\"barrel_jellyfish\")\n        elif pred == 1:\n            PredictedClass = \"'compass_jellyfish'\"\n            print(\"compass_jellyfish\")\n        elif pred == 2:\n            PredictedClass = \"'lions_mane_jellyfish'\"\n            print(\"lions_mane_jellyfish\")\n        elif pred == 3:\n            PredictedClass = \"'mauve_stinger_jellyfish'\"\n            print(\"mauve_stinger_jellyfish\")\n        elif pred == 4:\n            PredictedClass = \"'moon_jellyfish'\"\n            print(\"moon_jellyfish\")\n        elif pred == 5:\n            PredictedClass = \"'plastic_pollution'\"\n            print(\"plastic_pollution\")\n\n        # plt.imshow(image.astype(\"uint8\")) # Optional: display the image\n        # plt.show()\n\n        # Append the image filename and predicted class to the submit list\n        file = file.split('.')[0]\n        submit.append((file, PredictedClass))\n\n# Write the predictions to a CSV file\nfields = [\"ImageID\", 'PredictedClass']\ncsv_writer(\"TurtleVisionChallenge_Predictions_fineTuned.csv\", fields, submit)\n\n# A csv file contains the predicted classes for the test set of the TurtleVisionChallenge dataset.","metadata":{"id":"a32c4de1"},"outputs":[],"execution_count":null}]}